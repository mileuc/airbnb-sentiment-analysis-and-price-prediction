{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-sJ5mXdN1VJ"
      },
      "source": [
        "# Extract Subsets from Reviews Data and Clean Up for Modeling and Labelling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac6VLxKgN1VM",
        "outputId": "a32ca555-b484-409c-96cc-f1c94e7866db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=95a4596577bcdfadc683c9c8ccb2a07d29946b1051f98b45dde167b9e276cd59\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=e61a058e943994729c433dcbec0e80e4cf7d5eab7c01bbd7e3971d9bd38624af\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Collecting spark-nlp==5.1.4\n",
            "  Downloading spark_nlp-5.1.4-py2.py3-none-any.whl (540 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.7/540.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-5.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect # Library to detect language of review text\n",
        "!pip install pyspark\n",
        "!pip install spark-nlp==5.1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required Libaries and Methods"
      ],
      "metadata": {
        "id": "kC8nPv6xxowV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4qgXXuj7N1VO"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, regexp_replace\n",
        "from pyspark.ml import Pipeline\n",
        "import sparknlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initiate SparkContext and SparkSession and Import Google Drive Module"
      ],
      "metadata": {
        "id": "dRImwB92h_ew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q-0vc0iyTbPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1bc131-c010-4442-e7f3-8ed5c5fb5f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version: 5.1.4\n",
            "Apache Spark version: 3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Create a SparkSession\n",
        "spark=SparkSession.builder.appName('ENSF-612').getOrCreate()\n",
        "\n",
        "# Check version of the Spark NLP library and Apache Spark being used in the\n",
        "# current Spark session\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a2Z5ZDHBTf2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10fa9c4b-0fb2-41e8-be01-ef3922ff62cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Imports the drive module from the google.colab library\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounts your Google Drive into the Colab environment at the specified directory path /content/drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYlOJw1xN1VP"
      },
      "source": [
        "Function to Convert CSV to DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "alRSlpv9N1VQ"
      },
      "outputs": [],
      "source": [
        "# Method to convert CSV to pandas DataFrame\n",
        "def csv_to_df(file_path):\n",
        "    \"\"\"\n",
        "      Converts a CSV file to a pandas DataFrame\n",
        "\n",
        "      Parameters:\n",
        "         file_path: The path to the CSV file, to be converted into a DataFrame\n",
        "\n",
        "      Return:\n",
        "         df: The newly created pandas DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    # File location and type\n",
        "    # file_location = \"/content/drive/My Drive/ENSF-612/project-files/\" + fileName  # Combine the filename with the /Filestore/tables/ path in DataBricks\n",
        "    file_type = \"csv\" # Specify that the file type is a CSV. Other file types will be ignored.\n",
        "\n",
        "    # CSV options\n",
        "    infer_schema = \"true\" # Infer schema automatically while reading the CSV\n",
        "    first_row_is_header = \"true\" # Treat the first row as header\n",
        "    delimiter = \",\" # Define the delimiter used in the CSV file\n",
        "\n",
        "   # Read the CSV file into a DataFrame using Spark\n",
        "   # Allowing multiline entries in the CSV\n",
        "   # Specifying an escape character for CSV entries\n",
        "    df = spark.read.format(file_type) \\\n",
        "         .option(\"inferSchema\", infer_schema) \\\n",
        "         .option(\"header\", first_row_is_header) \\\n",
        "         .option(\"sep\", delimiter) \\\n",
        "         .option(\"multiline\",\"True\") \\\n",
        "         .option(\"escape\",\"\\\"\") \\\n",
        "         .load(file_path)\n",
        "\n",
        "    # Return DataFrame\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the reviews"
      ],
      "metadata": {
        "id": "nACcyhBQiIxk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Cq568cfuN1VR"
      },
      "outputs": [],
      "source": [
        "# Load csv data and convert it to a DataFrame\n",
        "\n",
        "fileName = \"reviews.csv\"\n",
        "filePath = \"/content/drive/My Drive/ENSF-612/project-files/\" + fileName\n",
        "entire_df = csv_to_df(filePath)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a subset of the reviews and inspect the data"
      ],
      "metadata": {
        "id": "V74uZJaXid4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# take a subset of ~100,000 reviews for less processing\n",
        "sample_fraction = 0.1\n",
        "reviews_df = entire_df.sample(fraction=sample_fraction, seed=42)\n",
        "reviews_df.show()\n",
        "reviews_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4pzHG-QieZw",
        "outputId": "71dadbe0-408f-438a-d426-81e852ffabc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+-----+-----------+--------------+----------------------------------+\n",
            "|listing_id|                id| date|reviewer_id| reviewer_name|                          comments|\n",
            "+----------+------------------+-----+-----------+--------------+----------------------------------+\n",
            "|     13913|          11876590|41746|    5194009|    Alessandro|              Alina was a perfe...|\n",
            "|     13913|         538005731|43737|    7253695|          Bart|              Alina is an amazi...|\n",
            "|     13913|         543287825|43745|   28531625|        Philip|              Felt at home - Al...|\n",
            "|     15400|            528262|40799|     969713|       Valerie|              Delightful, charm...|\n",
            "|     15400|           1491714|41076|    2384243| José Henrique|              We've been travel...|\n",
            "|     98541|           3289231|41280|    4000934|       Cameron|              This worked out v...|\n",
            "|     98541|           5755533|41470|    6650608|           Jim|              We were a group o...|\n",
            "|     15400|           3290846|41280|    1457643|     Alexander|              Philippa was a ve...|\n",
            "|     15400|           8967459|41607|    9235247|     Dorothy B|              Wonderful locatio...|\n",
            "|     15400|          15264060|41826|   11959525|       Michael|              Philippa’s little...|\n",
            "|     15400|          23566366|41978|    2984861|           Roy|              A wonderful place...|\n",
            "|     98541|          50967526|42293|   29696460|         Kosta|              The host canceled...|\n",
            "|     98541|         102473733|42631|    8001658|        Olivia|              Alicja was helpfu...|\n",
            "|     98541|         125183627|42739|   73931317|         Allan|              Everything was ni...|\n",
            "|     98541|         298947993|43311|  187944705|         Ariel|              The host canceled...|\n",
            "|     15400|          38136941|42198|    3321262|      Beth Ann|              We had a wonderfu...|\n",
            "|    264779|         275084233|43261|   12061881|        Monica|              This is a great l...|\n",
            "|    264779|450525034935998000|44452|  141477602|           Jai|              We stayed in the ...|\n",
            "|    264779|669366217170349000|44754|  457185869|            Sk|숙소는 쾌적하고 호스트님도 친절...|\n",
            "|     15400|         109100609|42662|   96743710|Carlos Roberto|              En general fue un...|\n",
            "+----------+------------------+-----+-----------+--------------+----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105142"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "xjIubFxMioS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows\n",
        "num_rows = reviews_df.count()\n",
        "\n",
        "# Get the number of columns\n",
        "num_columns = len(reviews_df.columns)\n",
        "\n",
        "# Display the shape (number of rows and columns)\n",
        "print(\"Number of rows: \", num_rows)\n",
        "print(\"Number of columns: \", num_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebu0ASRUQRQo",
        "outputId": "8419ad92-600d-4f22-cb4f-26700fb6b30e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows:  105142\n",
            "Number of columns:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the original number of rows\n",
        "original_count = reviews_df.count()\n",
        "\n",
        "# Remove duplicates and count the remaining rows\n",
        "distinct_count = reviews_df.dropDuplicates().count()\n",
        "\n",
        "# Calculate the count of duplicate rows\n",
        "duplicate_count = original_count - distinct_count\n",
        "\n",
        "# Display the count of duplicate rows\n",
        "print(\"Number of duplicate rows: \", duplicate_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4qN0u7GQRKD",
        "outputId": "a3ba70f1-c7ca-4167-dcf2-09acafb3712e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "View column names"
      ],
      "metadata": {
        "id": "QnKIJzjkirUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = reviews_df.columns\n",
        "print(column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVF5EuiIQRCh",
        "outputId": "ddfe1edf-2111-4394-8cb3-39aeae782877"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for missing values"
      ],
      "metadata": {
        "id": "jzDJBbn5iv09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, isnan, when\n",
        "\n",
        "# Check for missing values in each column\n",
        "reviews_df.select([count(when(isnan(c), c)).alias(c) for c in reviews_df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjVZNdJ-QbPp",
        "outputId": "d51b9171-5ec3-4bba-e3ce-0a3c21155aa5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+----+-----------+-------------+--------+\n",
            "|listing_id| id|date|reviewer_id|reviewer_name|comments|\n",
            "+----------+---+----+-----------+-------------+--------+\n",
            "|         0|  0|   0|          0|           10|       0|\n",
            "+----------+---+----+-----------+-------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values in the columns that we care about, which are listing_id and comments"
      ],
      "metadata": {
        "id": "U-3pQbQPxzxj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4eEvGYrN1VU"
      },
      "source": [
        "### Filtering Out Non-English Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ttLiR59eN1VU"
      },
      "outputs": [],
      "source": [
        "# Import the BooleanType class from the pyspark.sql.types module\n",
        "from pyspark.sql.types import BooleanType\n",
        "from pyspark.sql.functions import udf\n",
        "from langdetect import detect # Import the detect method from the langdetect library\n",
        "\n",
        "\n",
        "# Define a User Defined Function (UDF) named 'check_if_english'\n",
        "@udf(returnType=BooleanType())\n",
        "def check_if_english(text):\n",
        "    \"\"\"\n",
        "        Takes text as input and returns a BooleanType indicating if the text is in English.\n",
        "\n",
        "        Parameters:\n",
        "            text: The string of text whose language is to be analyzed\n",
        "\n",
        "        Returns:\n",
        "            language: A boolean that is True if the language is in english.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to detect the language of the 'text' using the 'detect' function from langdetect\n",
        "        language = detect(text)\n",
        "    except:\n",
        "        # If an exception occurs (e.g., due to non-text input), set 'language' to \"error\".\n",
        "        language = \"error\"\n",
        "    # Return True if the detected language is English ('en'), otherwise return False.\n",
        "    return language == 'en'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extract a subset of reviews for listings with >= 20 reviews\n",
        "We do this because we will eventually take an average sentiment score for each listing"
      ],
      "metadata": {
        "id": "SeUoTN_Ax9Yr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4kVcNNqgSdIX"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of reviews for each listing\n",
        "listing_counts = reviews_df.groupBy(\"listing_id\").count()\n",
        "\n",
        "# Filter listings with at least 20 reviews\n",
        "popular_listings = listing_counts.filter(col(\"count\") >= 20)\n",
        "\n",
        "# Perform an inner join of the reviews DataFrame with the popular listings to\n",
        "# get only the rows corresponding to listings with at least 20 reviews\n",
        "df_with_counts = reviews_df.join(popular_listings, \"listing_id\", \"inner\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91-GFtoGzrh0"
      },
      "source": [
        "Get the first 20 reviews for each listing with at least 20 reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q2Ay3DSc-QKG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Use the 'check_if_english' UDF to filter reviews based on whether the 'comments' are in English.\n",
        "english_reviews = df_with_counts.filter(check_if_english('comments'))\n",
        "\n",
        "# Add a row number partitioned by listing_id and ordered by review id\n",
        "window_spec = Window.partitionBy(\"listing_id\").orderBy(\"id\")\n",
        "\n",
        "# Alias the count column to avoid naming conflicts\n",
        "df_with_row_number = english_reviews.withColumn(\"review_num\", F.count(\"id\").over(window_spec).alias(\"review_num\"))\n",
        "\n",
        "# Here we need to only take the reviews for listings with >= 20 reviews\n",
        "# Calculate the number of reviews for each listing\n",
        "df_with_num_reviews = df_with_row_number.groupBy(\"listing_id\").count().withColumnRenamed(\"count\", \"num_reviews\").cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U8q-qvSfyoBx"
      },
      "outputs": [],
      "source": [
        "# Filter listings with at least 20 reviews\n",
        "df_listings_with_20_english_reviews = df_with_num_reviews.filter(col(\"num_reviews\") >= 20)\n",
        "\n",
        "# limit the subset to 500 listings, therefore ~10,000 reviews\n",
        "first_500_listings = df_listings_with_20_english_reviews.limit(500)\n",
        "\n",
        "# Get the remaining listings with over 20 reviews, for extracting a subset for manual labelling\n",
        "remaining_listings = df_listings_with_20_english_reviews.subtract(first_500_listings)\n",
        "\n",
        "# perform an inner join to get the reviews\n",
        "df_20_english_reviews = df_with_row_number.join(first_500_listings, \"listing_id\", \"inner\")\n",
        "remaining_reviews = df_with_row_number.join(remaining_listings, \"listing_id\", \"inner\")\n",
        "\n",
        "\n",
        "# Select the first 20 reviews for 750 popular listing (15,000 rows)\n",
        "selected_reviews = df_20_english_reviews.filter(col(\"review_num\") <= 20).limit(10000)\n",
        "reviews_for_labeling = remaining_reviews.filter(col(\"review_num\") <= 20).limit(1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C5uikMyQpdan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a0c752-72f8-4c8f-e114-de6bc59079af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[listing_id: int, id: bigint, date: int, reviewer_id: int, reviewer_name: string, comments: string, count: bigint, review_num: bigint, num_reviews: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Cache the dataframes for future use\n",
        "selected_reviews.cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zHJwuywnpj7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee7579a-6bb1-4a83-c762-55b799bcbdbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-----+-----------+-------------+--------------------+-----+----------+-----------+\n",
            "|listing_id|       id| date|reviewer_id|reviewer_name|            comments|count|review_num|num_reviews|\n",
            "+----------+---------+-----+-----------+-------------+--------------------+-----+----------+-----------+\n",
            "|     90700|   691142|40851|     157881|     Jennifer|We had a fantasti...|   42|         1|         38|\n",
            "|     90700|  1297706|41047|    1579008|       Lauren|Great Host and ve...|   42|         2|         38|\n",
            "|     90700|  1718326|41106|    2376989|      Rebecca|This was a great ...|   42|         3|         38|\n",
            "|     90700|  2700334|41206|    3554326|        Adlan|This apartment is...|   42|         4|         38|\n",
            "|     90700|  5255190|41446|     174904|     Agustina|Very nice apartme...|   42|         5|         38|\n",
            "|     90700|  6105473|41485|    1965535|    Christina|Lovely location, ...|   42|         6|         38|\n",
            "|     90700|  6554999|41503|    3863823|         Anne|we had wonderful ...|   42|         7|         38|\n",
            "|     90700|  6767676|41510|    8126385|     Kayleigh|Good location, ri...|   42|         8|         38|\n",
            "|     90700| 11657039|41740|   11239982|      Deborah|We found the flat...|   42|         9|         38|\n",
            "|     90700| 11911124|41748|    7368606|       Lauren|Great location in...|   42|        10|         38|\n",
            "|     90700| 19039463|41887|    1700335|         Rose|Chil welcomed me ...|   42|        11|         38|\n",
            "|     90700| 20223905|41908|    2610455|        Robyn|What a great loca...|   42|        12|         38|\n",
            "|     90700| 23706938|41981|    7278161|         Lars|We had a really n...|   42|        13|         38|\n",
            "|     90700| 24086379|41992|   13144990|       Magali|We had a great ti...|   42|        14|         38|\n",
            "|     90700| 24807168|42007|    9924196|         Nick|Great flat in a g...|   42|        15|         38|\n",
            "|     90700| 28982012|42096|    4282920|       Emilia|Great location! C...|   42|        16|         38|\n",
            "|     90700| 46261612|42256|   26354767|        Lacey|Chil was a wonder...|   42|        17|         38|\n",
            "|     90700| 62982788|42419|    1779692|         Ryan|Chil was responsi...|   42|        18|         38|\n",
            "|     90700| 65217486|42441|   46204524|      Janetta|The location of t...|   42|        19|         38|\n",
            "|     90700| 82115856|42547|    1644593|     Mauricio|The place is grea...|   42|        20|         38|\n",
            "|    244125|  3647990|41332|    4847087|        Fabio|It was great stay...|   28|         1|         25|\n",
            "|    244125|  7279956|41531|    7026345|        Ahmed|The flat, the pla...|   28|         2|         25|\n",
            "|    244125| 11343218|41729|    9433381|       Marcin|Great views, nice...|   28|         3|         25|\n",
            "|    244125| 12414585|41760|   13785141|       Karine|First of all, we ...|   28|         4|         25|\n",
            "|    244125| 18648948|41881|   15526153|        Peter|Claire was very f...|   28|         5|         25|\n",
            "|    244125| 19918622|41902|   21434521|      Jessica|The reservation w...|   28|         6|         25|\n",
            "|    244125| 21708469|41934|    9527158|         Matt|Clare's place was...|   28|         7|         25|\n",
            "|    244125| 22721776|41955|   23381760|       Rachel|Despite being in ...|   28|         8|         25|\n",
            "|    244125| 23954535|41988|    8788325|       Romain|Everything was pe...|   28|         9|         25|\n",
            "|    244125| 25297403|42015|   10831496|         Luke|Claire's place is...|   28|        10|         25|\n",
            "|    244125| 25420054|42019|   24375360|        Cliff|Nice apartment, g...|   28|        11|         25|\n",
            "|    244125| 26302228|42044|    2142533|       Didier|Perfect area, nea...|   28|        12|         25|\n",
            "|    244125| 37280389|42191|   24058013|      Marissa|An incredible apa...|   28|        13|         25|\n",
            "|    244125|109402434|42664|   14537505|        Putri|Located in the hi...|   28|        14|         25|\n",
            "|    244125|115905679|42701|   21294698|         Lina|We staid only for...|   28|        15|         25|\n",
            "|    244125|148693926|42856|   10721394|          Ann|This place is a g...|   28|        16|         25|\n",
            "|    244125|247373503|43187|    3998734|     Michelle|Claire is fabulou...|   28|        17|         25|\n",
            "|    244125|335191664|43384|    4048211|     Patricia|Claire's place is...|   28|        18|         25|\n",
            "|    244125|538020865|43737|   66254879|      Kathryn|Really gorgeous f...|   28|        19|         25|\n",
            "|    244125|577424740|43814|   99490100|      Shannon|We had a great st...|   28|        20|         25|\n",
            "|    280234|   986824|40978|    1312032|        Filiz|Helen was very he...|   38|         1|         31|\n",
            "|    280234|  1222769|41032|     691917|      Kirsten|GREAT and central...|   38|         2|         31|\n",
            "|    280234|  1687153|41101|    2838922|      Andreas|Small room, but g...|   38|         3|         31|\n",
            "|    280234|  2592522|41194|    2772282|    Chaitanya|It would be diffi...|   38|         4|         31|\n",
            "|    280234|  2731695|41209|    3747727|      Desmond|AMAZING HOST!!!\\r...|   38|         5|         31|\n",
            "|    280234|  3708818|41339|    5021261|      Li Ting|The location was ...|   38|         6|         31|\n",
            "|    280234|  8328520|41573|    4970482|       Sophie|Great location.  ...|   38|         7|         31|\n",
            "|    280234|  9294474|41627|    4105465| Michelangelo|I had a great sta...|   38|         8|         31|\n",
            "|    280234| 10903073|41710|    2164468|      Clement|Great central loc...|   38|         9|         31|\n",
            "|    280234| 12782571|41770|   13361556|       Mickey|The best part of ...|   38|        10|         31|\n",
            "+----------+---------+-----+-----------+-------------+--------------------+-----+----------+-----------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "reviews_for_labeling.cache()\n",
        "reviews_for_labeling.show(50)\n",
        "reviews_for_labeling.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XDz3VdY8R_Vp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3119a5f8-a77a-44b5-b15a-00cef092c5ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[listing_id: int, num_reviews: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# clear some cached dataframes from memory\n",
        "# reviews_count_df.unpersist()\n",
        "# listing_counts.unpersist()\n",
        "df_with_num_reviews.unpersist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4Xq6601eqB1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8865a9a-79f8-4ea6-f35f-c861df46bf3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "reviews_for_labeling.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hpiMVFQKExYx"
      },
      "outputs": [],
      "source": [
        "# selected_reviews.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNQGzKvexrfi"
      },
      "source": [
        "Check if any of the listings selected have fewer than 20 reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9YFpWkvje1yA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0befb86c-d2d9-4505-ad8e-6e3100b00b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|listing_id|total_reviews|\n",
            "+----------+-------------+\n",
            "|     90700|           20|\n",
            "|    244125|           20|\n",
            "|    280234|           20|\n",
            "|    358360|           20|\n",
            "|    375006|           20|\n",
            "|    390319|           20|\n",
            "|    390320|           20|\n",
            "|    390356|           20|\n",
            "|    390618|           20|\n",
            "|    412652|           20|\n",
            "|    436458|           20|\n",
            "|    439489|           20|\n",
            "|    454008|           20|\n",
            "|    469187|           20|\n",
            "|    523749|           20|\n",
            "|    544824|           20|\n",
            "|    583705|           20|\n",
            "|    599058|           20|\n",
            "|    620164|           20|\n",
            "|    627123|           20|\n",
            "+----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df_listings_for_labeling = reviews_for_labeling.groupBy(\"listing_id\").count().withColumnRenamed(\"count\", \"total_reviews\").orderBy(\"total_reviews\", ascending=False)\n",
        "df_listings_for_labeling.cache()\n",
        "df_listings_for_labeling.show()\n",
        "df_listings_for_labeling.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jSjXuLJPzIQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5421d86b-ae72-4eae-84c9-d2044e65ff2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[listing_id: int, total_reviews: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df_selected_listings = selected_reviews.groupBy(\"listing_id\").count().withColumnRenamed(\"count\", \"total_reviews\").orderBy(\"total_reviews\", ascending=True)\n",
        "df_selected_listings.cache()\n",
        "# df_selected_listings.show()\n",
        "# df_selected_listings.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uPFrsgKJ42t2"
      },
      "outputs": [],
      "source": [
        "# drop unneccessary pre-processing columns\n",
        "columns_to_drop = [\"count\", \"num_reviews\"]\n",
        "reviews_for_labeling = reviews_for_labeling.drop(*columns_to_drop)\n",
        "selected_reviews = selected_reviews.drop(*columns_to_drop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgUW3B5R43OU"
      },
      "source": [
        "### Filter Out HTML Tags and punctuation in Reviews with regex\n",
        "This is required for importing the data into Label Studio for manual labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rmW75xiB58k9"
      },
      "outputs": [],
      "source": [
        "def clean_reviews(df, original_column=\"comments\"):\n",
        "  html_pattern = \"<.*?>\"                 # replace with a single space\n",
        "  multiple_spaces_pattern = \"\\\\s+\"       # replace multiple space with a single space\n",
        "  comma_newline_pattern  = \",|\\r\\n?|\\n\"  # includes comma, carriage return, newline chars\n",
        "\n",
        "  # intermediate column names\n",
        "  no_html_tags_column = \"comments_no_html\"\n",
        "  cleaned_column=\"comments_cleaned\"\n",
        "\n",
        "  # Apply the pattern to remove HTML tags\n",
        "  df_no_html = df.withColumn(no_html_tags_column, regexp_replace(col(original_column), html_pattern, \" \"))\n",
        "\n",
        "  # Apply the patterns to replace multiple spaces with a single space and commas/newline characters with an empty string\n",
        "  df_cleaned = df_no_html.withColumn(cleaned_column, regexp_replace(regexp_replace(col(no_html_tags_column), multiple_spaces_pattern, \" \"), comma_newline_pattern, \"\"))\n",
        "\n",
        "  # Drop temporary columns\n",
        "  columns_to_drop = [\"count\", \"num_reviews\", original_column, no_html_tags_column]\n",
        "  df_cleaned = df_cleaned.drop(*columns_to_drop)\n",
        "\n",
        "  # Rename cleaned comments column back to original column name\n",
        "  df_cleaned = df_cleaned.withColumnRenamed(cleaned_column, original_column)\n",
        "\n",
        "  return df_cleaned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "W0AyoLWQ79I5"
      },
      "outputs": [],
      "source": [
        "# apply cleaning function to dataframes\n",
        "cleaned_reviews_for_labeling = clean_reviews(reviews_for_labeling)\n",
        "cleaned_selected_reviews = clean_reviews(selected_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KN77Dyo5d8RD"
      },
      "outputs": [],
      "source": [
        "# Write the DataFrames to a CSV file\n",
        "path = \"/content/drive/MyDrive/ENSF-612/project-files/\"\n",
        "cleaned_reviews_for_labeling.write.csv(path + \"temp_1000_reviews_for_labeling.csv\", header=True, mode=\"overwrite\")\n",
        "cleaned_selected_reviews.write.csv(path + \"temp_selected_10000_reviews.csv\", header=True, mode=\"overwrite\")\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "2-filter-reviews",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ensf-ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}